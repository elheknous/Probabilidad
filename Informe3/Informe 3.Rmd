---
title: "Informe 3"
author: "José Matus"
date: "2023-06-02"
output: 
  html_document:
    toc: true
    toc_depth: 4
    toc_float: true
    collapsed: true
    smooth_scroll: true
    theme: journal
    highlight: kate
    df_print: paged
    code_folding: show
---

```{r message = FALSE, warning = FALSE}
library(tidyverse)
library(GGally)
library(corrplot)
library(dplyr)
library(ggplot2)
library(car)
library(readxl)
library(nortest)
library(ggfortify)
library(lmtest)
library(gamlss)
library(ppcor)
library(MASS)

datos <- read_excel("C:/Users/josem/Downloads/MATUS_TORO_JOSE (1).xlsx")

```

# Análisis de variable

La variable a analizar será la presión (PRES)

## Limpieza de datos

```{r message = FALSE, warning = FALSE}
cajaPres = datos %>%   
  ggplot(aes(y=PRES)) +
  geom_boxplot() +  
  coord_flip()
cajaPres
```

Observando el diagrama de caja se puede notar que no existen datos atípicos, por lo tanto, se realizaran los modelos de regresión con la cantidad total de los datos

## Selección de la variable

Para definir la variable, primero quitaremos la variable año de la base de datos debido a que los datos estudiados fueron extraídos todos del año 2013 por lo tanto, esta variable, no aporta nada al estudio que se desea realizar

```{r message = FALSE, warning = FALSE}
aire <- datos %>% dplyr :: select(-year)
corrplot(cor(aire),
         method="color",      
         addCoef.col = "black",  
         number.cex=0.9,  
         tl.col="black",  
         tl.srt=45)

```

# Modelos

## Modelo 1 (Lineal simple)

Para el modelo de regresión lineal simple escogeremos la variable TEMP (temperatura) como predictor ya que, como se puede observar en el cuadro anterior, esta es la variable que tiene una relación mas fuerte con la presión (-0.73)

```{r message = FALSE, warning = FALSE}
modelo1 <- lm(PRES ~ TEMP, data = aire)
summary(modelo1) #0.5304

```

Teniendo en cuenta el R\^2 obtenido, a continuación crearemos un nuevo modelo que excluya los datos atípicos del modelo anterior para así comparar y ver que modelo predice mejor la variable de estudio

```{r message = FALSE, warning = FALSE}
#outlierTest(modelo1)
puntosAtipicos <- influencePlot(modelo1)
inffluyentesAtipcos = as.numeric(rownames(puntosAtipicos))
modeloSinPuntoM1 = lm(PRES ~ TEMP , data = aire %>% 
              dplyr :: slice(-inffluyentesAtipcos))

summary(modeloSinPuntoM1) #0.5375


aire %>% 
  ggplot(aes(TEMP,PRES))+
  geom_point()+
  geom_abline(intercept = modeloSinPuntoM1$coefficients[1],
              slope = modeloSinPuntoM1$coefficients[2],
              col="purple",linewidth=2)
```

Debido a que al quitar los datos atípicos el R\^2 aumenta ligeramente, escogeremos al modelo sin los puntos influyentes como el mod1, además de que al ver la gráfica pareciera que el modelo se ajusta bien

```{r message = FALSE, warning = FALSE}

mod1 = modeloSinPuntoM1
```

## Modelo 2 (Lineal múltiple)

A continuación, se realizará el modelo de regresión lineal múltiple empezando por el modelo que contempla todas las variables

```{r}
modeloFull <- lm(PRES ~ .,data = aire) # 0.6166
summary(modeloFull)
vif(modeloFull)

```

Ya que el modeloFull consta con un vif muy bajo en cada variable podemos concluir que este no posee multicolinealidad por lo tanto no es necesario ajustar el modelo con el ppcor

Observando el modeloFull, procederemos a quitar las variables con menos significancia, creando modelos individuales sin ellas, para luego crear un último modelo sin todas estas variables (hour, PM2.5, SO2, RAIN)

**Modelo sin PM2.5**

```{r}
ma = lm(PRES ~., data = aire %>% dplyr :: select(-PM2.5)) # 0.6169 
summary(ma)
vif(ma)
```

**Modelo sin RAIN**

```{r}
mb = lm(PRES ~., data = aire %>% dplyr :: select(-RAIN)) # 0.6145
summary(mb)
vif(mb)
```

**Modelo sin RAIN y PM2.5**

```{r}
mb2 = lm(PRES ~., data = aire %>% dplyr :: select(-RAIN,-PM2.5)) # 0.6148
summary(mb2)
vif(mb2)
```

**Modelo sin RAIN, PM2.5 y hour**

```{r}
mb3 = lm(PRES ~., data = aire %>% dplyr :: select(-RAIN,-PM2.5,-hour)) # 0.612
summary(mb3)
vif(mb3)
```

**Modelo sin hour**

```{r}
mc = lm(PRES ~., data = aire %>% dplyr :: select(-hour)) # 0.6135 
summary(mc)
vif(mc)
```

**Modelo sin hour y PM2.5**

```{r}
mc2 = lm(PRES ~., data = aire %>% dplyr :: select(-hour,-PM2.5)) # 0.6138
summary(mc2)
vif(mc2)
```

**Modelo sin SO2**

```{r}
md = lm(PRES ~., data = aire %>% dplyr :: select(-SO2)) # 0.6136
summary(md)
vif(md)
```

**Modelo sin SO2 y PM2.5**

```{r}
md2 = lm(PRES ~., data = aire %>% dplyr :: select(-SO2,-PM2.5)) # 0.6132
summary(md2)
vif(md2)
```

**Modelo sin PM2.5, hour, RAIN y SO2**

```{r}
me = lm(PRES ~., data = aire %>% dplyr :: select(-PM2.5,-hour,-RAIN,-SO2)) # 0.6076
summary(me)
vif(me)


```

Al crear los modelos mencionados anteriormente podemos notar que el vif en todos se mantiene muy cercano a uno, así que podemos asegurar que no existe una correlación en ningún modelo.

Al analizar el R\^2 de los modelos es fácil ver que no existe una gran variación en este, siendo el más alto 0.6169 y el más bajo 0.6076 así que, para este caso, seleccionaremos el modelo me como el mod2 ya que, pese al tener el R\^2 mas bajo, es el que posee menos variables lo que facilita bastante el análisis, además de que una variación del R\^2 del 1% aproximadamente es casi irrelevante

```{r}
puntosAtipicos <- influencePlot(me)
inffluyentesAtipcos = as.numeric(rownames(puntosAtipicos))
modeloSinPuntoM2 = lm(PRES ~ . , aire %>% dplyr :: select(-PM2.5,-hour,-RAIN,-SO2) %>% 
              dplyr :: slice(-inffluyentesAtipcos))

summary(modeloSinPuntoM2) #0.6178
```

Volviendo a realizar el mismo proceso que con el modelo anterior, notamos que el modelo sin errores posee un leve incremento de R\^2 así que utilizaremos este como el mod2

```{r}
mod2 = modeloSinPuntoM2
```

## Modelo 3 (Backward)

```{r}
mod3 <- stepAIC(lm(PRES ~ ., data = aire),
                 direction = "backward")
summary(mod3)

```

# Selección de modelo

## Supuestos

### Normalidad 

#### mod1

```{r}
autoplot(mod1)[2]
plot(density(mod1$residuals))
nortest::lillie.test(mod1$residuals) #0.01092
```

#### mod2

```{r}
autoplot(mod2)[2]
plot(density(mod2$residuals))
nortest::lillie.test(mod2$residuals) #0.06737
```

#### mod3

```{r}
autoplot(mod3)[2]
plot(density(mod3$residuals))
nortest::lillie.test(mod3$residuals) #0.08422
```


### Independencia

#### mod1

```{r}

plot(mod1,which = 1)
lmtest::dwtest(mod1) #2.2e-16
```

#### mod2
```{r}

plot(mod2,which = 1)
lmtest::dwtest(mod2)#2.2e-16
```


#### mod3
```{r}

plot(mod3,which = 1)
  lmtest::dwtest(mod3) #0.0001623
```


### Homocedasticidad

#### mod1

```{r}
autoplot(mod1)[1]
lmtest::bptest(mod1)#0.0001177
```

#### mod2

```{r}
autoplot(mod2)[1]
lmtest::bptest(mod2) #0.000336
```


#### mod3
```{r}
autoplot(mod3)[1]
lmtest::bptest(mod3) #1.016e-06
```


## AIC

### mod1

```{r}
AIC(mod1)
```


### mod2
```{r}
AIC(mod2)
```


### mod3
```{r}
AIC(mod3)
```
Analizando los supuestos y sus respectivos valores de sus p-value podemos observar que ningún modelo cumple con los supuestos de independencia y homocedasticidad, sin embargo, el mod2 y mod3 cumplen con el supuesto de normalidad, viendo el p-value de ambos, notamos que el mayor es del mod3, además de que al ver su AIC este el menor de los tres, por lo tanto, escogeremos al mod3 para predecir el comportamiento de la variable PRESS

# Predicción

```{r}
newAire = data.frame(month = 4, hour = 18, SO2 = 14,
                     NO2 = 17, TEMP = 13.8,RAIN =0.0)

predict(mod3,newdata = newAire)
```

